Na podstawie dostarczonych obrazów, które przedstawiają wyniki testów wydajnościowych Gatling dla scenariusza z profilem obciążenia wynoszącym "1000 użytkowników * 3 podczas 90 sekund" (co prawdopodobnie oznacza $3000$ użytkowników z ramp-upem lub spike'em trwającym 90 sekund), możemy sformułować następujące podsumowanie:

**1. Profil Obciążenia (Stress Test):**

* **Liczba aktywnych użytkowników (Active Users along the Simulation):** Wykres "Active Users along the Simulation" pokazuje, że liczba aktywnych użytkowników narastała stopniowo, osiągając szczyt w okolicach $1000$ (lub nieco więcej, ciężko precyzyjnie odczytać wartość z osi Y) między $14:55:20$ a $14:55:40$, a następnie stopniowo spadała. To potwierdza, że był to test obciążeniowy lub stress test z narastającym obciążeniem.
* **Żądania na sekundę (Number of requests per second):** Liczba żądań na sekundę również rosła wraz z liczbą aktywnych użytkowników, osiągając szczyt w okolicach 100-120 żądań/sekundę, a następnie spadała.
* **Odpowiedzi na sekundę (Number of responses per second):** Wykres "Number of responses per second" (pokazujący również odpowiedzi OK i KO) ma podobny kształt do wykresu żądań na sekundę, co oznacza, że system próbował odpowiadać na napływające żądania.

**2. Ogólne Wyniki Wykonania:**

* **Całkowita liczba żądań:** $3000$
* **Liczba udanych żądań (OK):** $3000$
* **Liczba nieudanych żądań (KO):** $0$
* **Procent udanych żądań:** $100\%$ OK, $0\%$ KO.
    * **Wniosek:** Mimo wysokiego obciążenia, system nie zwrócił żadnych błędów z perspektywy kodu odpowiedzi HTTP (wszystkie żądania zakończyły się statusem OK). Jest to pozytywny sygnał dotyczący stabilności, ale trzeba szczegółowo przeanalizować czasy odpowiedzi.

**3. Czasy Odpowiedzi (Response Time - kluczowy wskaźnik dla tego testu):**

* **Średni czas odpowiedzi (Mean):** $8403$ ms (około $8.4$ sekundy).
* **Minimalny czas odpowiedzi (Min):** $452$ ms.
* **Maksymalny czas odpowiedzi (Max):** $18367$ ms (około $18.4$ sekundy).
* **Odchylenie standardowe (Standard Deviation):** $5862$ ms.
    * **Wniosek:** Średni czas odpowiedzi jest bardzo wysoki ($>8$ sekund), co jest nieakceptowalne dla większości aplikacji internetowych. Wysokie odchylenie standardowe wskazuje na dużą zmienność czasów odpowiedzi, co sugeruje niestabilność działania pod obciążeniem.

* **Percentyle czasu odpowiedzi:**
    * **50. percentyl (mediana):** $8881$ ms - połowa żądań zajęła ponad $8.8$ sekundy.
    * **75. percentyl:** $14043$ ms - $25\%$ żądań zajęło ponad $14$ sekund.
    * **95. percentyl:** $16530$ ms - $5\%$ żądań zajęło ponad $16.5$ sekundy.
    * **99. percentyl:** $17481$ ms - $1\%$ żądań zajęło ponad $17.4$ sekundy.
    * **Wniosek:** Czasy odpowiedzi dla wyższych percentyli są ekstremalnie wysokie, co wskazuje, że znacząca część użytkowników doświadczała bardzo długich opóźnień.

* **Rozkład czasu odpowiedzi (Response Time Distribution):** Wykres "Response Time Distribution" oraz "Response Time Ranges" jasno pokazują, że:
    * Znaczna większość żądań ($2250$ z $3000$) mieści się w zakresie `t >= 1200 ms` (czyli ponad $1.2$ sekundy).
    * Niewielka część ($452$) zmieściła się w zakresie `t < 800 ms`.
    * Bardzo mało ($298$) w zakresie `t >= 800 ms i t < 1200 ms`.
    * Nie ma błędów oznaczonych jako "failed" (czerwone).
    * Histogram "Response Time Distribution" pokazuje, że odpowiedzi grupują się wokół wyższych wartości, z kilkoma szczytami w okolicach $200$ ms, ale dominującą liczbą odpowiedzi rozłożoną w szerokim zakresie powyżej $3000$ ms, co potwierdza bardzo długie czasy.

* **Czasy odpowiedzi percentylowe w czasie (Response Time Percentiles over Time):** Wykres ten jest kluczowy. Pokazuje, że wraz ze wzrostem liczby aktywnych użytkowników (pomarańczowa linia) i liczby żądań na sekundę (niebieska linia pod spodem), czasy odpowiedzi (szczególnie $90$ i $95$ percentyl) gwałtownie wzrosły, osiągając wartości powyżej $10$ sekund (nawet do $18$ sekund dla maks.). Oznacza to, że system staje się bardzo powolny pod wysokim obciążeniem.

**Podsumowanie i wnioski:**

* **Stabilność (brak błędów):** System jest stabilny pod względem funkcjonalnym pod wysokim obciążeniem, ponieważ nie generuje błędów HTTP (`0% KO`). To jest pozytywna cecha.
* **Wydajność (czasy odpowiedzi):** System ma poważne problemy z wydajnością pod obciążeniem. Czasy odpowiedzi gwałtownie rosną wraz ze wzrostem liczby aktywnych użytkowników i żądań, stając się nieakceptowalnie długie (średnio ponad $8$ sekund, a dla $99$ percentyla prawie $18$ sekund).
* **Wąskie gardła:** Istnieje jasne wskazanie na wąskie gardło wydajnościowe, które powoduje, że system nie jest w stanie przetwarzać żądań wystarczająco szybko, gdy obciążenie wzrasta. Może to być związane z:
    * Niewystarczającymi zasobami serwera (CPU, pamięć, sieć).
    * Problemami z bazą danych (blokady, wolne zapytania, zbyt mała pula połączeń).
    * Inefektywnym kodem aplikacji (problemy z algorytmami, synchronizacją, I/O).
    * Wąskimi gardłami w usługach zewnętrznych, od których zależy aplikacja.

**Kolejne kroki:**

1.  **Analiza zasobów:** Sprawdź zużycie zasobów (CPU, RAM, dysk I/O, sieć) na serwerach aplikacji i baz danych w trakcie testu.
2.  **Analiza logów:** Przejrzyj logi aplikacji i serwera pod kątem błędów, ostrzeżeń lub wzorców, które mogą wskazywać na problemy wydajnościowe.
3.  **Profilowanie aplikacji:** Użyj narzędzi do profilowania kodu aplikacji, aby zidentyfikować najbardziej czasochłonne metody lub operacje.
4.  **Optymalizacja bazy danych:** Sprawdź wydajność zapytań SQL, indeksy, konfigurację pul połączeń.
5.  **Stopniowe testowanie:** Jeśli to możliwe, wykonaj testy z mniejszymi, stopniowo rosnącymi obciążeniami, aby precyzyjnie zlokalizować punkt, w którym system zaczyna zwalniać.
6.  **Ulepszenia infrastruktury/kodu:** Po zidentyfikowaniu wąskich gardeł, wdróż optymalizacje (np. zwiększenie zasobów, optymalizacja kodu, poprawa konfiguracji bazy danych) i powtórz testy.
